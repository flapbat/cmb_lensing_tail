{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd38608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from pysr import PySRRegressor, TemplateExpressionSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import camb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51f847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,1,2,3,4,5]).reshape(-1,1)\n",
    "y = np.array([3, 4, 7, 11, 19, 28]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0b8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = TemplateExpressionSpec(\n",
    "    expressions = [\"g\"],\n",
    "    variable_names = [\"x\"],\n",
    "    parameters = {\"beta\": 2},\n",
    "    combine = \"g(x)/beta[2] + beta[1]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea44d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PySRRegressor(\n",
    "    niterations = 1, #100\n",
    "    binary_operators = [\"+\", \"-\", \"*\", \"pow\"],  #allowed operations\n",
    "    constraints = {'pow': (4, 1), \"*\": (4, 4)},   #enforces maximum complexities on arguments of operators \n",
    "    batching = True, \n",
    "    batch_size = 1, #10000\n",
    "    maxsize = 30,\n",
    "    populations = 20,\n",
    "    expression_spec = template,\n",
    "    complexity_of_variables = 2, #global complexity of variables\n",
    "    procs = 4,\n",
    "    loss_function_expression = \"\"\"\n",
    "    using DynamicExpressions: DynamicExpressions as DE\n",
    "    function my_loss(tree, dataset::Dataset{T,L}, options) where {T,L}\n",
    "        prediction, flag = eval_tree_array(tree, dataset.X, options)\n",
    "        if !flag\n",
    "            return L(Inf)\n",
    "            end\n",
    "        function node_penalty(node)\n",
    "            is_con = node.degree == 0 && node.constant\n",
    "            if is_con \n",
    "                val = node.val\n",
    "                print(val)\n",
    "            end\n",
    "        end\n",
    "        for node in tree\n",
    "            node_penalty(node.val)\n",
    "        end\n",
    "        return sum((prediction .- dataset.y) .^ 2) / dataset.n\n",
    "    end\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234c3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/miniconda/envs/megan/lib/python3.9/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "Compiling Julia backend...\n"
     ]
    },
    {
     "ename": "JuliaError",
     "evalue": "MethodError: no method matching iterate(::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}})\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  iterate(!Matched::CompositeException, Any...)\n   @ Base task.jl:55\n  iterate(!Matched::DataStructures.IntSet)\n   @ DataStructures ~/.julia/packages/DataStructures/IrAJn/src/int_set.jl:171\n  iterate(!Matched::DataStructures.IntSet, !Matched::Int64)\n   @ DataStructures ~/.julia/packages/DataStructures/IrAJn/src/int_set.jl:173\n  ...\n\nStacktrace:\n  [1] my_loss(tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5})\n    @ Main ./none:14\n  [2] evaluator(f::typeof(my_loss), tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, idx::Nothing)\n    @ SymbolicRegression.LossFunctionsModule ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:134\n  [3] eval_loss(tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}; regularization::Bool, idx::Nothing)\n    @ SymbolicRegression.LossFunctionsModule ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:153\n  [4] eval_loss\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:139 [inlined]\n  [5] update_baseline_loss!\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:225 [inlined]\n  [6] _validate_options(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multithreading, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5})\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:597\n  [7] _equation_search(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multithreading, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, saved_state::Nothing)\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:567\n  [8] equation_search(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}; options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, saved_state::Nothing, runtime_options::Nothing, runtime_options_kws::@Kwargs{niterations::Int64, parallelism::String, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, heap_size_hint_in_bytes::Nothing, worker_imports::Nothing, runtests::Bool, return_state::Bool, run_id::String, verbosity::Int64, logger::Nothing, progress::Bool, v_dim_out::Val{1}})\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:561\n  [9] equation_search\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:542 [inlined]\n [10] #equation_search#23\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:511 [inlined]\n [11] equation_search\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:456 [inlined]\n [12] #equation_search#24\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:535 [inlined]\n [13] pyjlany_call(self::typeof(equation_search), args_::Py, kwargs_::Py)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/any.jl:44\n [14] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/base.jl:73\n [15] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n    @ PythonCall.JlWrap.Cjl ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/C.jl:63",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJuliaError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/megan/lib/python3.9/site-packages/pysr/sr.py:2318\u001b[0m, in \u001b[0;36mPySRRegressor.fit\u001b[0;34m(self, X, y, Xresampled, weights, variable_names, complexity_of_variables, X_units, y_units, category)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint()\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;66;03m# Perform the search:\u001b[39;00m\n\u001b[0;32m-> 2318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[38;5;66;03m# Then, after fit, we save again, so the pickle file contains\u001b[39;00m\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;66;03m# the equations:\u001b[39;00m\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_equation_file:\n",
      "File \u001b[0;32m~/miniconda/envs/megan/lib/python3.9/site-packages/pysr/sr.py:2109\u001b[0m, in \u001b[0;36mPySRRegressor._run\u001b[0;34m(self, X, y, runtime_params, weights, category, seed)\u001b[0m\n\u001b[1;32m   2106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2107\u001b[0m     jl_y_variable_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2109\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mSymbolicRegression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequation_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjl_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjl_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_extra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mniterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mniterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names_in_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_variable_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_feature_names_in_\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_variable_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_y_variable_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjl_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_units_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2121\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjl_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_units_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_units_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_units_\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumprocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallelism\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallelism\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaved_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjulia_state_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddprocs_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheap_size_hint_in_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheap_size_hint_in_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_spec\u001b[38;5;241m.\u001b[39mwrite_hparams(logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m~/.julia/packages/PythonCall/L4cjh/src/JlWrap/any.jl:262\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m     return ValueBase.__dir__(self) + self._jl_callmethod($(pyjl_methodnum(pyjlany_dir)))\n\u001b[1;32m    261\u001b[0m def __call__(self, *args, **kwargs):\n\u001b[0;32m--> 262\u001b[0m     return self._jl_callmethod($(pyjl_methodnum(pyjlany_call)), args, kwargs)\n\u001b[1;32m    263\u001b[0m def __bool__(self):\n\u001b[1;32m    264\u001b[0m     return True\n",
      "\u001b[0;31mJuliaError\u001b[0m: MethodError: no method matching iterate(::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}})\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  iterate(!Matched::CompositeException, Any...)\n   @ Base task.jl:55\n  iterate(!Matched::DataStructures.IntSet)\n   @ DataStructures ~/.julia/packages/DataStructures/IrAJn/src/int_set.jl:171\n  iterate(!Matched::DataStructures.IntSet, !Matched::Int64)\n   @ DataStructures ~/.julia/packages/DataStructures/IrAJn/src/int_set.jl:173\n  ...\n\nStacktrace:\n  [1] my_loss(tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5})\n    @ Main ./none:14\n  [2] evaluator(f::typeof(my_loss), tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, idx::Nothing)\n    @ SymbolicRegression.LossFunctionsModule ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:134\n  [3] eval_loss(tree::TemplateExpression{Float32, TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, Node{Float32}, ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}, @NamedTuple{g::ComposableExpression{Float32, Node{Float32}, @NamedTuple{operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, eval_options::EvalOptions{false, false, true, Nothing}}}}, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}, operators::OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, variable_names::Nothing, parameters::@NamedTuple{beta::SymbolicRegression.TemplateExpressionModule.ParamVector{Float32}}}}, dataset::SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}; regularization::Bool, idx::Nothing)\n    @ SymbolicRegression.LossFunctionsModule ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:153\n  [4] eval_loss\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:139 [inlined]\n  [5] update_baseline_loss!\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/LossFunctions.jl:225 [inlined]\n  [6] _validate_options(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multithreading, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5})\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:597\n  [7] _equation_search(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multithreading, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, saved_state::Nothing)\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:567\n  [8] equation_search(datasets::Vector{SymbolicRegression.CoreModule.DatasetModule.BasicDataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}; options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, OperatorEnum{Tuple{typeof(+), typeof(-), typeof(*), typeof(safe_pow)}, Tuple{}}, Node, TemplateExpression, @NamedTuple{structure::TemplateStructure{(:g,), (:beta,), typeof(__sr_template_18158175872994894189), @NamedTuple{g::Int64}, @NamedTuple{beta::Int64}}}, MutationWeights, false, false, nothing, Nothing, 5}, saved_state::Nothing, runtime_options::Nothing, runtime_options_kws::@Kwargs{niterations::Int64, parallelism::String, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, heap_size_hint_in_bytes::Nothing, worker_imports::Nothing, runtests::Bool, return_state::Bool, run_id::String, verbosity::Int64, logger::Nothing, progress::Bool, v_dim_out::Val{1}})\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:561\n  [9] equation_search\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:542 [inlined]\n [10] #equation_search#23\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:511 [inlined]\n [11] equation_search\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:456 [inlined]\n [12] #equation_search#24\n    @ ~/.julia/packages/SymbolicRegression/MdISO/src/SymbolicRegression.jl:535 [inlined]\n [13] pyjlany_call(self::typeof(equation_search), args_::Py, kwargs_::Py)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/any.jl:44\n [14] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/base.jl:73\n [15] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n    @ PythonCall.JlWrap.Cjl ~/.julia/packages/PythonCall/L4cjh/src/JlWrap/C.jl:63"
     ]
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree::TemplateExpression\n",
    "#tree::Union{AbstractExpressionNode,AbstractExpression}\n",
    "#using DynamicExpressions: DynamicExpressions as DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd41d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54da8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megan",
   "language": "python",
   "name": "megan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
